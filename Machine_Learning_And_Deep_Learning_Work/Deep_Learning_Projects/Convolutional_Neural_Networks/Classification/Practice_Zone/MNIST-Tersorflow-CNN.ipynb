{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b4cd889-dfce-4cb5-a542-5b0d0ec3529c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1be35014-e6e5-4722-90c4-01142b5b8272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist= tf.keras.datasets.mnist.load_data()\n",
    "(train_data,train_label) , (test_data,test_label) = mnist\n",
    "\n",
    "train_data.shape ,train_label.shape , test_data.shape,test_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "690cf085-315e-4e95-87c7-a1f0e3c96ef6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 10), (10000, 10))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "train_label_t = encoder.fit_transform(train_label.reshape(-1,1))\n",
    "test_label_t = encoder.transform(test_label.reshape(-1,1))\n",
    "\n",
    "train_label_t.shape ,test_label_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9dfc125-cbde-4756-b9aa-f13fbca41c6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 784), (10000, 784))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_t = train_data.reshape(60000,784,)\n",
    "test_data_t = test_data.reshape(10000,784,)\n",
    "train_data_t.shape,test_data_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93159895-2762-4968-a490-01b8a8436a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3136\n"
     ]
    }
   ],
   "source": [
    "input_width = 28\n",
    "input_height = 28 \n",
    "input_channels = 1\n",
    "input_pixels = 784\n",
    "\n",
    "n_conv1 = 32\n",
    "n_conv2 = 64\n",
    "conv1_k =5\n",
    "conv2_k =5\n",
    "stride_conv1 = 1\n",
    "stride_conv2 = 1\n",
    "\n",
    "max_pool1_k=2 ## i.e 2*2 max pooling on our images  \n",
    "max_pool2_k=2\n",
    "\n",
    "n_hidden = 1024\n",
    "n_out = 10 \n",
    "\n",
    "input_size_to_hidden = ( input_width//(max_pool1_k*max_pool2_k) )*( input_height//(max_pool1_k*max_pool2_k) )*n_conv2\n",
    "print(input_size_to_hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921f9ab1-1440-4e3f-b0ed-2d50a60d3d14",
   "metadata": {},
   "source": [
    "### Initialising Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8f58b32-c26e-469b-9763-67afa3ac5fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42\n",
    "weights ={\n",
    "    'wc1':tf.Variable(tf.compat.v1.random_normal([conv1_k,conv1_k,input_channels,n_conv1],seed = random_state)),\n",
    "    'wc2':tf.Variable(tf.compat.v1.random_normal([conv2_k,conv2_k,n_conv1,n_conv2],seed = random_state)),\n",
    "    'wh1':tf.Variable(tf.compat.v1.random_normal([input_size_to_hidden,n_hidden],seed = random_state)),\n",
    "    'wo':tf.Variable(tf.compat.v1.random_normal([n_hidden,n_out],seed = random_state)),\n",
    "}\n",
    "biases ={\n",
    "    'bc1':tf.Variable(tf.compat.v1.random_normal([n_conv1],seed = random_state)),\n",
    "    'bc2':tf.Variable(tf.compat.v1.random_normal([n_conv2],seed = random_state)),\n",
    "    'bh1':tf.Variable(tf.compat.v1.random_normal([n_hidden],seed = random_state)),\n",
    "    'bo':tf.Variable(tf.compat.v1.random_normal([n_out],seed = random_state)),\n",
    "}"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9a972b77-8024-4e54-b153-12f9da4c7127",
   "metadata": {},
   "source": [
    "stride in tf.nn.conv2d(x) requires List of size same as x.shape..i.e 4\n",
    "X.shape = [n_examples,length,width,depth]\n",
    "\n",
    "In stride = []\n",
    "\n",
    "1st argument = 1, as i want to move one by one ,rather skipping any image in between.\n",
    "\n",
    "2nd & 3rd argument = stride value ,as will move along length ,and width\n",
    "\n",
    "4th argument = 1 ,as we will not be moving along depth as along depth we are exactly going to fit the filter to image we have.\n",
    "\n",
    "## for biases we could have simply added .. but will use another function it as well .as it allow different size vector to add..( without creating much compexities )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c115124-bc3e-422d-a53e-d343a7ead2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv(X,weights,bias,strides=1):\n",
    "    out = tf.nn.conv2d(X,weights,padding='SAME',strides=[1,strides,strides,1])\n",
    "    out = tf.nn.bias_add(out,bias)\n",
    "    out = tf.nn.relu(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68fd228a-ccd1-4189-b366-4c5d512310e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxpooling(X,k=2):\n",
    "    out = tf.nn.max_pool(X,padding='SAME',ksize = [1,k,k,1],strides=[1,k,k,1])\n",
    "    return out "
   ]
  },
  {
   "cell_type": "raw",
   "id": "d529c699-a58b-4b47-8694-5885f64b9112",
   "metadata": {},
   "source": [
    "\n",
    "tf.reshape(x,shape[])\n",
    "\n",
    "> In shape[-1,a,b] pass the argument you are sure about and put -1.that you want reshape function to infer it by itself\n",
    "\n",
    ">> [making all size making sense ..i.e product is same as old matrix.]\n",
    "\n",
    "tf.nn.dropout(X,keep_prob)\n",
    "adding dropout layer\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb5e0a7e-d9e3-4cbd-96e2-e1ff8f294a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Forward Propagation............\n",
    "\n",
    "def cnn(X,weights,biases,keep_prob=0.8):\n",
    "    ## With reshape flattened images.\n",
    "\n",
    "    X = tf.reshape(X,shape=[-1,input_height,input_width,input_channels])\n",
    "\n",
    "    conv1 = conv(X,weights['wc1'],biases['bc1'],stride_conv1)\n",
    "    conv1_pool = maxpooling(conv1,max_pool1_k)\n",
    "    \n",
    "    conv2 = conv(conv1_pool,weights['wc2'],biases['bc2'],stride_conv2)\n",
    "    conv2_pool = maxpooling(conv2,max_pool2_k)\n",
    "    \n",
    "    hidden_input = tf.reshape(conv2_pool , shape=[-1,input_size_to_hidden])\n",
    "    hidden_output_before_activation = tf.add(tf.matmul(hidden_input,weights['wh1']),biases['bh1'])\n",
    "    hidden_output_before_dropout = tf.nn.relu(hidden_output_before_activation)\n",
    "    hidden_output = tf.nn.dropout(hidden_output_before_dropout,keep_prob)\n",
    "    \n",
    "    output = tf.add(tf.matmul(hidden_output,weights['wo']),biases['bo'])\n",
    "    \n",
    "    print('shapes of following are :')\n",
    "    print('conv1 :',conv1.shape)\n",
    "    print('conv1_pool :',conv1_pool.shape)\n",
    "    print('conv2 :',conv2.shape)\n",
    "    print('conv2_pool :',conv2_pool.shape)\n",
    "    print('hidden_input :',hidden_input.shape)\n",
    "    print('hidden_output :',hidden_output.shape)\n",
    "    print('output :',output.shape)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ff848bea-84fa-4434-8046-36142a8dc5f1",
   "metadata": {},
   "source": [
    "## Copyng Code from ,tensorflow notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e5878b2-5652-4a16-a110-a8dbd7684742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes of following are :\n",
      "conv1 : (None, 28, 28, 32)\n",
      "conv1_pool : (None, 14, 14, 32)\n",
      "conv2 : (None, 14, 14, 64)\n",
      "conv2_pool : (None, 7, 7, 64)\n",
      "hidden_input : (None, 3136)\n",
      "hidden_output : (None, 1024)\n",
      "output : (None, 10)\n"
     ]
    }
   ],
   "source": [
    "X = tf.compat.v1.placeholder('float',[None,input_pixels])\n",
    "Y = tf.compat.v1.placeholder(tf.int32,[None,n_out])\n",
    "keep_prob = tf.compat.v1.placeholder('float')\n",
    "\n",
    "pred  = cnn(X,weights,biases,keep_prob)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5f948d2c-0857-4122-b40e-5c56bdfd1f38",
   "metadata": {},
   "source": [
    "## Loss Function ..DOUBT SOLVING..\n",
    "\n",
    "## Note as our function is softmax ..so we will not need any activation on output layer\n",
    "\n",
    "## Very Very Important .. \n",
    "## basicaly when we are calulating Loss(i.e crosslogit ) than we have to make assure that we are using softmax on output ( 'softmax' for multilable classification , and 'sigmoid' for binary classification)\n",
    "\n",
    "## And tf.softmax_cross_entropy does that for you i.e both thing in one\n",
    "## So no need to use any external activation on output layer , as implicilty added in cost function ..\n",
    "\n",
    "## when we are calulating predict than we basicaly dont require any activation to get to answer as we take argmax ,, that will always remain same. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57756e40-1e2e-48ee-a80f-52dce4e4f9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred , labels=Y)) ## use v2 function as we will getts some deprecated warnning  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f99a9e1-3d08-4714-89d3-9cfcff6b9473",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=0.005)\n",
    "optimize = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59342e79-e95d-4ae3-b6dd-c6dce6d2904f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.compat.v1.Session()\n",
    "sess.run(tf.compat.v1.global_variables_initializer()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b61acd9-f8e8-4b80-bfe9-9f2a00805d08",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "batch_size = 100\n",
    "n_size = len(train_data_t)\n",
    "X_train = train_data_t\n",
    "Y_train = train_label_t\n",
    "index = np.arange(n_size)\n",
    "\n",
    "for i in range(1):\n",
    "    # np.random.shuffle(index)\n",
    "\n",
    "    # X_train = X_train[index]\n",
    "    # Y_train = Y_train[index]\n",
    "    \n",
    "    total_cost = 0\n",
    "    for j in range(batch_size , n_size , batch_size):\n",
    "        \n",
    "        batch_X = X_train[j-batch_size : j]\n",
    "        batch_Y = Y_train[j-batch_size : j]\n",
    "    \n",
    "        c,_ = sess.run([cost,optimize] , feed_dict={X:batch_X,Y:batch_Y,keep_prob:0.8})\n",
    "        total_cost += c ## Total cost is better to evealute overall perfromace ..\n",
    " \n",
    "    print(i,':',total_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e91f28-c12a-4671-8a84-dade179564a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = tf.argmax(pred,1) # axis=1 \n",
    "Y_true = tf.argmax(Y,1)\n",
    "\n",
    "Corrects = tf.equal(Y_pred , Y_true)\n",
    "\n",
    "Y_train_pred ,correct_train = sess.run( [Y_pred,Corrects] ,feed_dict = {X:train_data_t ,Y:train_label_t,keep_prob:1})\n",
    "Y_test_pred ,correct_test = sess.run( [Y_pred,Corrects] ,feed_dict = {X:test_data_t ,Y:test_label_t,keep_prob:1})\n",
    "\n",
    "print(\"Train Accuracy :\",correct_train.mean()) \n",
    "print(\"Test Accuracy :\",correct_test.mean()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcba9885-6d96-4672-baa4-c3481ddeb37c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "cefa094c-71b0-46ab-b4cf-0699be06f528",
   "metadata": {},
   "source": [
    "### Summary ............\n",
    "\n",
    "# For keep_prob:1\n",
    "\n",
    "## Epoch = 25\n",
    "#### Train Accuracy : 0.9977\n",
    "#### Test Accuracy : 0.9881\n",
    "\n",
    "## Epoch = 50\n",
    "#### Train Accuracy : 0.9991\n",
    "#### Test Accuracy : 0.9901\n",
    "\n",
    "#--------------------------------------------------------------------------#\n",
    "# For keep_prob:0.8  ## Even After putting 50 % percent weights to 0 it was performing preety good.\n",
    "\n",
    "## Epoch = 25\n",
    "#### Train Accuracy : 0.9979\n",
    "#### Test Accuracy : 0.9894\n",
    "\n",
    "## Epoch =50\n",
    "# Train Accuracy :  0.9979\n",
    "# Test Accuracy :   0.9878"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NeuralNetwork",
   "language": "python",
   "name": "neuralnetwork"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
