{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30665,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf  # model\nfrom tensorflow.keras import callbacks,models,layers,Sequential,metrics,losses,optimizers,applications  # model\nimport tensorflow_datasets as tfds  # for dataset\n\nimport numpy as np    # math Compuation\nimport matplotlib.pyplot as plt ## for ploting charts\\","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pathlib import Path\nimport PIL.Image as Image\nimport cv2\nfrom pprint import pprint\nfrom collections import Counter\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix,classification_report\nimport seaborn as sns\n\nimport os,shutil","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"raw","source":"Data of Eye Dataset \n    Link : \n    The dataset consists of \n    (i) Normal, \n    (ii) Diabetic Retinopathy, \n    (iii) Cataract \n    (iv) Glaucoma retinal \n    \n    ,images where each class have approximately 1000 images. These images are collected from various sorces like IDRiD, Oculur recognition, HRF etc.","metadata":{}},{"cell_type":"code","source":"# !pip install kaggle","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !mkdir .\\datasets\\kaggle\n# !cp kaggle.json ~/.kaggle/","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# shutil.rmtree('datasets/Saved_Model')\n# shutil.rmtree('WorkingFolder')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import os\n# os.environ['KAGGLE_USERNAME'] = 'prajwalsharma123'\n# os.environ['KAGGLE_KEY']='6719f9750ed948ff6d82400eab62fe8c'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !kaggle datasets download -d gunavenkatdoddi/eye-diseases-classification","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import zipfile\n\n# zip_path = 'eye-diseases-classification.zip'\n\n# with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n#     zip_ref.extractall('datasets')\n\n# os.remove(zip_path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_directory = 'datasets/dataset/'\nclass_names = ['normal','glaucoma','cataract','diabetic_retinopathy'] ## Name should be same name of classs in folder directory \nclass_short_names = ['normal','glaucoma','cataract','diabetic'] \n\ndataset_configuration={\n    '_batch_size':16,\n    '_seed' : 42,\n    \n    '_train_split':0.8,\n    '_val_split':0.1,\n    '_test_split':0.1,\n    \n    '_image_shape':(128,128,),\n    '_n_images':4217,\n    '_n_class':4,\n}\n\ngeneral_configuration = {\n    \"_n_epochs\": 50,\n    \"_learning_rate\": 0.01,\n}\n\nclassifier_configuration={\n    '_n_Dense1':128,\n    '_n_Dense2':16,\n    \"_dropout_rate\":0.15,\n    '_n_class':4,\n}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"raw","source":"Label Mode can be \n    \"int\" # Categorical Dataset normal\n    'categorical' #One Hot Encoded for Label\n    ","metadata":{}},{"cell_type":"markdown","source":"## > Data Collection","metadata":{}},{"cell_type":"code","source":"Dataset = tf.keras.utils.image_dataset_from_directory(\n    directory = data_directory,\n    labels = 'inferred', ## Labels will be generaed frm directory structure.\n    label_mode = 'categorical',\n    class_names = class_names, ## Not Neccessary As such .\n    color_mode = 'rgb',\n    batch_size = None,\n    image_size = dataset_configuration['_image_shape'],\n    shuffle = True,\n    seed = dataset_configuration['_seed'], ## TO have same shuffling\n\n    # validation_split=0.2, ## train_data \n    # subset='training', # as we setting vallidation split .\n) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def SplitData(dataset,TRAIN_RATIO,VAL_RATIO,TEST_RATIO,SIZE):\n    train_size = int(SIZE*TRAIN_RATIO)\n    val_size = int(SIZE*VAL_RATIO)\n    test_size = int(SIZE - train_size - val_size)\n    \n    dataset_configuration['_train_size'] = train_size\n    dataset_configuration['_val_size'] = val_size\n    dataset_configuration['_test_size'] = test_size\n    \n    train_dataset = dataset.take(train_size)\n    val_dataset = dataset.skip(train_size).take(val_size)\n    test_dataset = dataset.skip(train_size+val_size)\n    \n    return train_dataset,val_dataset,test_dataset","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TRAIN_RATIO = dataset_configuration['_train_split']\nVAL_RATIO = dataset_configuration['_val_split']\nTEST_RATIO = dataset_configuration['_test_split']\nSIZE = dataset_configuration['_n_images']\n\ntrain_dataset ,val_dataset,test_dataset =  SplitData(Dataset,TRAIN_RATIO,VAL_RATIO,TEST_RATIO,SIZE)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_dataset)\nprint(val_dataset)\nprint(test_dataset)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in val_dataset.take(1):\n    print(i)","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(16,8),facecolor='lightgrey')\nfor i,(image,label) in enumerate(train_dataset.take(32),1):\n    ax = plt.subplot(4,8,i)\n    plt.imshow(image/255.)\n    plt.title(class_names[np.argmax(label)][:8],fontsize=10)\n#     i+=1\n    plt.axis('off')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Augmentation","metadata":{}},{"cell_type":"markdown","source":"### > Layers","metadata":{}},{"cell_type":"raw","source":"## Observations : \n    > Images Were somewhat zoom in and zoom out ,along both axis \n    > Some Images were faded.(So we could use Contrast \n    > Third That our body is Symteric horizonaly so , same goes for eyes as well(so we can do split) \nConclusion : As There are many augmentaion possible so , lets add augmentaion layer in model, many augmentaions..","metadata":{}},{"cell_type":"code","source":"augment_layers = models.Sequential([\n    layers.RandomFlip(mode = 'horizontal'),\n#     layers.RandomRotation(factor=(-0.025,0.25)), #-9 degree to 9 degree\n    layers.RandomZoom(height_factor=(-0.2,0.2),width_factor=(-0.3,0.3),fill_mode='constant',fill_value=0),\n    layers.RandomContrast(factor=0.6),\n],name='augment_layers')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def augment(image,label):\n#     return augment_layers(image,training=True),label","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image,label = next(iter(train_dataset))\n\nplt.figure(figsize=(3,3))\nplt.imshow(image/255)\nplt.axis('off')\nplt.title('Previous Image')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12,5)).suptitle('Augmented Image for the previous Image',fontsize = 16)\nfor i in range(1,25,1):\n    aug_image = augment_layers(tf.expand_dims(image,0))[0]\n    \n    plt.subplot(3,8,i)\n    plt.imshow(aug_image/255)\n#     plt.imshow(image)\n\n    plt.axis('off')\n    plt.tight_layout()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Preparation","metadata":{}},{"cell_type":"code","source":"train_dataset=(\n    train_dataset\n#     .map(augment,num_parallel_calls=tf.data.AUTOTUNE) ## ony for train.\n    .batch(dataset_configuration['_batch_size'])\n    .prefetch(tf.data.AUTOTUNE)\n)\ntrain_dataset","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_dataset=(\n    val_dataset\n    .batch(dataset_configuration['_batch_size'])\n    .prefetch(tf.data.AUTOTUNE)\n)\nval_dataset","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test=[]\nY_test=[]\n\nfor images,labels in test_dataset:\n    Y_test.append(labels.numpy())  # contain batches\n    X_test.append(images.numpy())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test[0].shape,Y_test[0].shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# X_test = tf.concat([ tf.reshape(X_test[:-1],shape=(-1,)+image_shape+(3,) ) , X_test[-1:][0] ],axis=0)\n# Y_test = tf.concat()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# image_shape = configuration['_image_shape']\n# resize_rescale_layers = models.Sequential([\n#     layers.Resizing( image_shape[0],image_shape[1]),\n#     layers.Rescaling(1./255),\n# ])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Feature Extaction Models","metadata":{}},{"cell_type":"code","source":"class CustomConv2D(layers.Layer):\n    def __init__(self,n_filters,kernel_size,n_strides,padding='same',name = 'custom_conv2D'):\n        super(CustomConv2D,self).__init__(name=name)\n\n        self.conv = layers.Conv2D(\n            filters = n_filters,\n            kernel_size = kernel_size,\n            activation = 'relu',\n            strides = n_strides,\n            padding = padding, \n        )\n        self.batch_norm = layers.BatchNormalization()\n    \n    def call(self,x,training=True):\n        x = self.conv(x)\n        x = self.batch_norm(x,training = training)\n\n        return x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### > Resnet Model","metadata":{}},{"cell_type":"markdown","source":"#### Resudual Block","metadata":{}},{"cell_type":"code","source":"class ResidualBlock(layers.Layer):\n    def  __init__(self,n_channels,n_strides=1):\n        super(ResidualBlock,self).__init__(name='res_block')\n\n        self.dotted = (n_strides !=1)# if dimention are not same befor and after block . \n\n        self.custom_conv_1 = CustomConv2D(n_channels,3,n_strides)\n        self.custom_conv_2 = CustomConv2D(n_channels,3,1)\n        self.activation = layers.Activation('relu')\n\n        if(self.dotted):\n            self.custom_conv_3 = CustomConv2D(n_channels,1,n_strides)\n            ## To increse number of channels  size by 1.\n    \n    def call(self,input,training=None ):\n        x = self.custom_conv_1(input,training = training)\n        x = self.custom_conv_2(x,training = training)\n\n        ## Submissiong The output ..\n        if self.dotted:\n            x_add = self.custom_conv_3(input,training = training)\n            x_add = layers.Add()([x,x_add])\n        else:  ## if dimentions are same.\n            x_add = layers.Add()([x,input])\n\n        return self.activation(x_add)\n        ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"raw","source":"So we could easily shift from one model to other by just change the residual configuration","metadata":{}},{"cell_type":"code","source":"image_shape = dataset_configuration['_image_shape']\nclass ResNet34(models.Model):\n    def __init__(self):\n        super(ResNet34,self).__init__(name='resnet_34')\n        \n        self.input_1 = layers.InputLayer(shape = image_shape+(3,),name = 'Input'),\n        self.conv_1 = CustomConv2D(64,7,2,padding='same')\n        self.max_pool = layers.MaxPooling2D(3,2,padding = 'same',)\n   \n        self.conv_2_1 = ResidualBlock(64)\n        self.conv_2_2 = ResidualBlock(64)\n        self.conv_2_3 = ResidualBlock(64)\n\n        self.conv_3_1 = ResidualBlock(128,2) ## stride = 2 to downsample our feature.\n        self.conv_3_2 = ResidualBlock(128)\n        self.conv_3_3 = ResidualBlock(128)\n        self.conv_3_4 = ResidualBlock(128)\n        \n        self.conv_4_1 = ResidualBlock(256,2)\n        self.conv_4_2 = ResidualBlock(256)\n        self.conv_4_3 = ResidualBlock(256)\n        self.conv_4_4 = ResidualBlock(256)\n        self.conv_4_5 = ResidualBlock(256)\n        self.conv_4_6 = ResidualBlock(256)\n        \n        self.conv_5_1 = ResidualBlock(512,2)\n        self.conv_5_2 = ResidualBlock(512)\n        self.conv_5_3 = ResidualBlock(512)\n\n        self.global_pool = layers.GlobalAveragePooling2D(name = 'Output')\n\n    def call(self,x,training=None):\n\n        x = self.conv_1(x,training = training)\n        x = self.max_pool(x)\n\n        x = self.conv_2_1(x,training = training)\n        x = self.conv_2_2(x,training = training)\n        x = self.conv_2_3(x,training = training)\n        \n        x = self.conv_3_1(x,training = training)\n        x = self.conv_3_2(x,training = training)\n        x = self.conv_3_3(x,training = training)\n        x = self.conv_3_4(x,training = training)\n        \n        x = self.conv_4_1(x,training = training)\n        x = self.conv_4_2(x,training = training)\n        x = self.conv_4_3(x,training = training)\n        x = self.conv_4_4(x,training = training)\n        x = self.conv_4_5(x,training = training)\n        x = self.conv_4_6(x,training = training)\n    \n        x = self.conv_5_1(x,training = training)\n        x = self.conv_5_2(x,training = training)\n        x = self.conv_5_3(x,training = training)\n\n        output = self.global_pool(x)\n        return output\n        ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"resnet_34 = ResNet34()\n\nimage_shape = dataset_configuration['_image_shape']\nshape = (1,)+image_shape+(3,) \n\nresnet_34(tf.zeros(shape),training = False)\nresnet_34.summary()","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Lenet","metadata":{"jp-MarkdownHeadingCollapsed":true}},{"cell_type":"code","source":"def get_lenet_base_model():\n    n_filter1 = 16\n    n_filter2 = 6\n    kernel_size = 3\n    strides = 1\n    pool_size = 2\n    pool_strides = 2\n    \n    drop_rate = classifier_configuration['_dropout_rate']\n    image_shape = dataset_configuration['_image_shape']\n    \n    model = models.Sequential([\n        \n        layers.InputLayer(shape = image_shape+(3,)),\n\n        CustomConv2D(n_filter1 ,kernel_size ,strides , name='Conv_Norm_1'),\n        layers.MaxPool2D( pool_size = pool_size, \n                         strides = pool_strides, \n                         name = \"MaxPool1\"),\n        layers.Dropout(drop_rate,name = \"Dropout1\"),\n        \n        CustomConv2D(n_filter2,kernel_size,strides , name = 'Conv_Norm_2'),\n        layers.MaxPool2D( pool_size = pool_size, \n                         strides = pool_strides , \n                         name = \"MaxPool2\"),\n        layers.Dropout(drop_rate,name = \"Dropout2\"),\n    \n        layers.Flatten(name= \"Flatten\"),\n        \n    ],name = 'lenet_2')\n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lenet_2 = get_lenet_base_model()\nlenet_2.summary()","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### > Other Models (Pretrainied)","metadata":{}},{"cell_type":"code","source":"image_shape = dataset_configuration['_image_shape']\nefficientnet_v2b0 = applications.efficientnet_v2.EfficientNetV2B0(\n    weights='imagenet',  # Load weights pre-trained on ImageNet.\n    input_shape= image_shape + (3,),\n    include_top= False,\n    pooling='avg',\n    include_preprocessing=False\n)\n# efficientnet_v2m.trainable = True\nefficientnet_v2b0.summary()","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_shape = dataset_configuration['_image_shape']\n\nvgg_16 = applications.vgg16.VGG16(\n    weights='imagenet',  # Load weights pre-trained on ImageNet.\n    input_shape=image_shape + (3,),\n    include_top=False,\n    pooling='avg',\n)\n# vgg_16.trainable = True\nvgg_16.summary()","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_shape = dataset_configuration['_image_shape']\n\ninception_v3 = applications.inception_v3.InceptionV3(\n    weights = 'imagenet',  # Load weights pre-trained on ImageNet.\n    input_shape = image_shape + (3,),\n    include_top=False,\n    pooling='avg',\n)\n\n# inception_v3.trainable = True\ninception_v3.summary()","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_shape = dataset_configuration['_image_shape']\n\ndensenet_121 = applications.densenet.DenseNet121(\n    weights = 'imagenet',  # Load weights pre-trained on ImageNet.\n    input_shape = image_shape + (3,),\n    include_top = False,\n    pooling='avg',\n)\n# densenet_121.trainable = True\ndensenet_121.summary()","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Models CLassing ","metadata":{}},{"cell_type":"code","source":"# def BuildModel(base_model,model_name ,training):\n#     drop_rate = classifier_configuration['_dropout_rate']\n#     n_unit_1 = classifier_configuration['_n_Dense1']\n#     n_unit_2 = classifier_configuration['_n_Dense2']\n#     n_class = classifier_configuration['_n_class']\n#     image_shape = dataset_configuration['_image_shape']\n    \n#     ## -------------------------------------------------------------------------//\n#     fn_input = layers.Input(shape = (None ,None,3),name = 'Input')\n    \n#     x = layers.Rescaling(1.0/255,name = 'Rescale')(fn_input)\n#     x = layers.Resizing(height=image_shape[0],width = image_shape[1] ,name = 'Resize')(x)\n#     x = augment_layers(x)\n#     x = base_model(x , training = training)\n\n#     x = layers.Dense(n_unit_1,activation = \"relu\",name = \"Dense1\")(x)\n#     x = layers.BatchNormalization(name = 'Norm1')(x)\n#     x = layers.Dropout(drop_rate,name = 'Dropout1')(x)\n    \n#     x = layers.Dense(n_unit_2,activation = \"relu\" , name = \"Dense2\")(x)\n#     x = layers.BatchNormalization(name = 'Norm2')(x)\n#     x = layers.Dropout(drop_rate, name = 'Dropout2')(x)\n    \n#     fn_output = layers.Dense(n_class,activation = \"softmax\", name = \"Output\")(x)\n        \n#     Model = models.Model(fn_input,fn_output,name = model_name)\n#     ## --------------------------------------------------------------------------------//\n#     return Model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plateau_callback = callbacks.ReduceLROnPlateau(\n    monitor='val_accuracy',\n    factor=0.7, ## reduce by this factor . ## lr = lr*0.1\n    patience=5, ## wait till these number of epochs ,\n    verbose=1,\n    mode='auto', ## similar to what studied above,,i..e Min or Max..\n    min_delta=0.01, ## if change is less than delta than we will consider it as no improvement . \n    cooldown=0,  ## to wait after we have updated our lr ,,\n    min_lr=0, ## dont go below this lr.\n)\n\nloss_function = losses.CategoricalCrossentropy()\n# loss_function = losses.SparseCategoricalCrossentropy()\n\nmetrics_ = [metrics.CategoricalAccuracy(name='accuracy'),\n           metrics.TopKCategoricalAccuracy(k=2,name ='top_k_accuracy'),\n          ] \n\ndef AddFromTo(History,history):\n    for metric,values  in history.history.items():\n        if(metric not in History.keys()):\n            History[metric]=[]\n        History[metric]+=values\n    return History","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Base_logs_path ='WorkingFolder/logs/'\nModel_path ='datasets/Saved_Model/{}.keras'\nModel_weights_path = 'datasets/Saved_Model/{}_best.weights.h5'\n\nModel_dict = {}\nHistory_dict = {}\n    \ndef ModelsPipeLine(model_name ,base_model ,is_pretrained=False ,training=True , lr=0.01 ,n_epoch=100):    \n    n_epoch = n_epoch\n    lr = lr\n    History = {}\n    model_log_path     = Base_logs_path + model_name\n    model_weights_path = Model_weights_path.format(model_name)\n    model_path         = Model_path.format(model_name)\n\n    print(model_name.upper())\n    ## -------------------------Buld Model --------------------------------//\n#     BuildModel(base_model,model_name,training)\n    ## Classifier Paramters --------------------------------//\n    drop_rate = classifier_configuration['_dropout_rate']\n    n_unit_1 = classifier_configuration['_n_Dense1']\n    n_unit_2 = classifier_configuration['_n_Dense2']\n    n_class = classifier_configuration['_n_class']\n    image_shape = dataset_configuration['_image_shape']\n    \n    ## -------------------------------------------------------------------------//\n    \n    fn_input = layers.Input(shape = (None ,None,3),name = 'Input')\n    \n    x = layers.Rescaling(1.0/255,name = 'Rescale')(fn_input)\n    x = layers.Resizing(height=image_shape[0],width = image_shape[1] ,name = 'Resize')(x)\n    x = augment_layers(x)\n    \n    x = base_model(x , training = training)\n\n    x = layers.Dense(n_unit_1,activation = \"relu\",name = \"Dense1\")(x)\n    x = layers.BatchNormalization(name = 'Norm1')(x)\n    x = layers.Dropout(drop_rate,name = 'Dropout1')(x)\n    \n    x = layers.Dense(n_unit_2,activation = \"relu\" , name = \"Dense2\")(x)\n    x = layers.BatchNormalization(name = 'Norm2')(x)\n    x = layers.Dropout(drop_rate, name = 'Dropout2')(x)\n    \n    fn_output = layers.Dense(n_class,activation = \"softmax\", name = \"Output\")(x)\n        \n    Model = models.Model(fn_input,fn_output,name = model_name)\n    \n    ## --------------------------------------------------------------//\n    print(model_name +\"Model Builded\")\n    \n    ## Callbacks---------------------------------------------------------##\n    \n    checkpoint_callback = callbacks.ModelCheckpoint(  ## To save Best Models\n        model_weights_path,\n        monitor = 'val_accuracy',\n        verbose = 0,\n        save_best_only = True, ## will save best weights. \n        save_weights_only = True, ## If false will save whole model .. .\n        mode = 'max', # if monitor val_loss that it will be min else if val_accuracy that it will be Max..\n        save_freq = 'epoch', ## we will do this after every epoch .\n    )\n    \n    tensorboard_callback = callbacks.TensorBoard(model_log_path)\n    ## -TransferLearning-------------------------------------------------------##\n    if(is_pretrained):\n        print('TransferLearnining Begins')\n        base_model.trainable = False\n        n_epoch = int(n_epoch/2)\n        \n        Model.compile(\n            optimizers.Adam(learning_rate=lr),\n            loss = loss_function,\n            metrics = metrics_,\n        )\n        history = Model.fit(\n            train_dataset,\n            validation_data= val_dataset,\n            epochs = n_epoch,\n            verbose=1,\n            callbacks = [checkpoint_callback,\n                         plateau_callback,\n                         tensorboard_callback,\n                        ]\n        )\n        History = AddFromTo(History,history)\n        base_model.trainable = True\n        lr = lr/10  \n        \n    #-----------------------------------------------------------------------#.\n    print(\"Full Training begins\")\n    \n    Model.compile(\n        optimizers.Adam(learning_rate=lr),\n        loss = loss_function,\n        metrics = metrics_,\n    )\n\n    history = Model.fit(\n        train_dataset,\n        validation_data= val_dataset,\n        epochs = n_epoch,\n        verbose=1,\n        callbacks = [checkpoint_callback,\n                     plateau_callback,\n                     tensorboard_callback,\n                    ]\n    )\n    print('Saving Model and Results Begin')\n    History = AddFromTo(History,history)\n    \n    Model.load_weights(model_weights_path)\n    os.remove(model_weights_path)\n\n    Model.save(model_path)  # now we have the best Model.\n\n    Model_dict[model_name] = Model\n    History_dict[model_name] = History  \n        ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # ## Model Dictionary have model name with  Model\n# BaseModel_dict = {\n#     'lenet_2' : lenet_2,\n#     'resnet_34': resnet_34,\n#     'inception_v3': inception_v3,\n#     'densenet_121': densenet_121,\n#     'vgg_16': vgg_16,\n#     'efficientnet_v2m' :efficientnet_v2m,\n# }","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_name = 'efficientnet_v2b0'\nbase_model = efficientnet_v2b0\nis_pretrained = True\ntraining = False\n\nModelsPipeLine(model_name ,base_model ,is_pretrained ,training)","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_name = 'resnet_34'\nbase_model = resnet_34\nis_pretrained = False\ntraining = True\n\nModelsPipeLine(model_name ,base_model ,is_pretrained ,training)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Model_dict","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"History_dict","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nModel.load_weights(model_weights_path)\nos.remove(model_weights_path)\n\nModel.save(model_path)  # now we have the best Model.\n\nModel_dict[model_name] = Model\nHistory_dict[model_name] = History  ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Plots","metadata":{"jp-MarkdownHeadingCollapsed":true}},{"cell_type":"code","source":"# History1 = history1.history\n# History2 = history2.history","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### > Comparision","metadata":{"jp-MarkdownHeadingCollapsed":true}},{"cell_type":"code","source":"models_name_list = list(History_dict.keys())\nmetric_List = list(History_dict[models_name_list[0]].keys())\n\nplt.figure(figsize = (12,14),facecolor='#beb068').suptitle(\"Model Performance Comparision\",fontsize=16, y=1)\n\nfor i,metric in enumerate(metric_List,1):\n    plt.subplot(4,2,i)\n    \n    for model_name in models_name_list:\n        plt.plot(History_dict[model_name][metric],label= model_name,linewidth=1.5)\n        \n    plt.title(metric)\n    plt.legend()\n    plt.ylabel(metric + ' -->')\n    plt.xlabel('epoch -->')\n    plt.tight_layout()\n    plt.grid()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### > Performance","metadata":{}},{"cell_type":"code","source":"models_name_list = list(History_dict.keys())\nmetric_List = list(History_dict[models_name_list[0]].keys())\n\nfor model_name in models_name_list:\n    plt.figure(figsize = (16,4),facecolor='#beb068').suptitle(model_name+\" Performance\",fontsize=16, y=1)\n    for i,metric in enumerate(metric_List[:3],1):\n        plt.subplot(1,3,i)\n        plt.plot(History_dict[model_name][metric],label='train',linewidth=2)\n        plt.plot(History_dict[model_name]['val_'+ metric],label='validation',linewidth=1.5)\n        plt.title(metric)\n        plt.legend()\n        plt.ylabel(metric + ' -->')\n        plt.xlabel('epoch -->')\n        plt.subplots_adjust(wspace=0.2, hspace=0.3) \n        plt.grid()\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Evaluation","metadata":{}},{"cell_type":"code","source":"# Y_test =  tf.concat([np.argmax(Y_test[:-1],axis=-1).flatten(),np.argmax(Y_test[-1],axis=-1)],axis=0)\n# Y_test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# X_test = tf.concat([ tf.reshape(X_test[:-1],shape=(-1,)+image_shape+(3,) ) , X_test[-1:][0] ],axis=0)\n# X_test.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_true = np.argmax(Y_test , axis = -1)\nY_pred = effecient_model.predict(X_test,verbose=0) \nY_pred = np.argmax(np.array(Y_pred),axis=-1","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models_name_list = list(History_dict.keys())\nY_pred_dict = {}\nY_true = np.argmax(Y_test , axis = -1)\n\nfor model_name, model in Model_dict.items():\n    Y_pred = model.predict(X_test,verbose=0)    \n    Y_pred_dict[model_name] = np.argmax(np.array(Y_pred),axis=-1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### > Classification Report","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import classification_report","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models_name_list = list(History_dict.keys())\n\nfor model_name ,Y_pred in Y_pred_dict.items():\n    print(model_name.upper())\n    print(classification_report(Y_true,Y_pred))\n    print('>-----------------------------------------------------------------------------------<','\\n')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### > Confusion Matrix","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sn\n\nplt.figure(figsize=(12,6),facecolor='#beb068').suptitle(\"Confusion Matrix\",fontsize=16,y=0.95)\n\nfor i,(model_name,Y_pred) in enumerate(Y_pred_dict.items(),1):\n    \n    cn = tf.math.confusion_matrix(labels=Y_true,predictions=Y_pred)\n    \n    plt.subplot(2,3,i)\n    sn.heatmap(cn ,annot=True , fmt = 'd',xticklabels=class_short_names ,yticklabels=class_short_names,)\n    plt.xlabel(\"____Predicted____\",fontsize=14)\n    plt.ylabel(\"_____Truth______\" ,fontsize=12)\n    plt.yticks(rotation = 0)\n    plt.tight_layout()\n    plt.title(model_name)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Testing","metadata":{"jp-MarkdownHeadingCollapsed":true}},{"cell_type":"markdown","source":"import matplotlib.pyplot as plt\n\nfig = plt.figure(constrained_layout=True)\n\nsubfigs = fig.subfigures(2, 2)\n\nfor outerind, subfig in enumerate(subfigs.flat):\n    subfig.suptitle(f'Subfig {outerind}')\n    axs = subfig.subplots(2, 1)\n    for innerind, ax in enumerate(axs.flat):\n        ax.set_title(f'outer={outerind}, inner={innerind}', fontsize='small')\n        ax.set_xticks([])\n        ax.set_yticks([])\n \nplt.show()","metadata":{}},{"cell_type":"code","source":"Images = X_test[:16]\nLabels = Y_true[:16]\n\n\nmodel_list = [Model_dict['resnet_34'], Model_dict['lenet_2']]\nmodel_names = ['resnet_34','lenet_2']\n    \nfig = plt.figure(figsize=(10,6),facecolor='lightgrey')\n\nsubfigs = fig.subfigures(1,len(model_list), wspace=0.1)\n\nfor subfig,model,model_name in zip(subfigs.flat,model_list,model_names):\n\n    subfig.suptitle(model_name,y=1,fontsize=16)\n\n    axs = subfig.subplots(4,4,)\n\n    for i,ax in enumerate(axs.flat,0):\n        ax.imshow(images[i]/255.)\n\n        true = class_names[labels[i]]\n\n        image = tf.expand_dims(images[i],axis=0)\n        pred = model(image)[0]\n#         pred = resnet_34(image)[0]\n        pred = class_names[tf.argmax(pred,axis=-0).numpy()]\n\n        ax.set_title(f'{true} : {pred}',fontsize=10)\n        ax.axis('off')\n        plt.subplots_adjust(hspace=0.0,wspace=0.0)\n        plt.tight_layout()\nfig.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Saving Results","metadata":{}},{"cell_type":"markdown","source":"### > Model_History","metadata":{}},{"cell_type":"code","source":"import json\ns=json.dumps(book)\n\nwith open(\"History/History_dict.txt\",\"wb\") as file: \n    ## will create This directory along with file .. and will write s onto it ..\n    file.write(s)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ## Reteriving \n\n# with open(\"History/History_dict.txt\",\"r\") as file: # ;'r' for reading \n#     History_str = f.read(); ## it is a JSON String\n# History_dict_ = json.loads(History_str)\n# History_dict_","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### > Tensorboard","metadata":{}},{"cell_type":"code","source":"# %reload_ext tensorboard\n# %tensorboard --logdir $Base_logs_path --port=6025","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### >Models To WandB","metadata":{}},{"cell_type":"code","source":"import os\n# !wandb login --relogin 86e08e73408ad569e47977710a0d5253d116f899\n!wandb login 86e08e73408ad569e47977710a0d5253d116f899\nos.environ['WANDB_NOTEBOOK_NAME'] = 'Part10_MLOPS.ipynb'","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wandb.tensorboard.patch(root_logdir=Base_logs_path)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import wandb\n# from wandb.keras import WandbEvalCallback ,WandbCallback,WandbMetricsLogger, WandbModelCheckpoint","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wandb.init(project='EyeDiseaseDetection',\n           entity='creater',\n          )","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wandb.run","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wandb,finish()","metadata":{},"execution_count":null,"outputs":[]}]}